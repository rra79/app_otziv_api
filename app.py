import time
import requests
import pandas as pd
import streamlit as st
from io import BytesIO

# ================= CONFIG =================
st.set_page_config(
    page_title="App Store Reviews Dashboard",
    page_icon="ðŸ“Š",
    layout="wide"
)

# ================= UI =================
st.title("ðŸ“± App Store â€” ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²")
st.caption("Ð¡Ð±Ð¾Ñ€ + Ð´Ð°ÑˆÐ±Ð¾Ñ€Ð´Ñ‹ â€¢ Apple RSS API")

APP_ID = st.text_input("App ID Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ", placeholder="686449807")

REGIONS = st.multiselect(
    "Ð ÐµÐ³Ð¸Ð¾Ð½Ñ‹ App Store",
    options=[
        "ru","us","gb","de","fr","it","es","ca","au","jp","kr","br","mx",
        "pl","nl","se","no","fi","dk","tr","ae","sa","in"
    ],
    default=["ru"]
)

col1, col2 = st.columns(2)
START = col1.button("ðŸš€ ÐÐ°Ñ‡Ð°Ñ‚ÑŒ ÑÐ±Ð¾Ñ€", use_container_width=True)
STOP = col2.button("â›” ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ", use_container_width=True)

st.divider()

# ================= STATE =================
if "stop" not in st.session_state:
    st.session_state.stop = False
if STOP:
    st.session_state.stop = True

# ================= SENTIMENT =================
POSITIVE = {"Ñ…Ð¾Ñ€Ð¾Ñˆ", "Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½", "ÐºÐ»Ð°ÑÑ", "ÑÑƒÐ¿ÐµÑ€", "Ð»ÑŽÐ±Ð»ÑŽ", "ÑƒÐ´Ð¾Ð±Ð½"}
NEGATIVE = {"Ð¿Ð»Ð¾Ñ…", "ÑƒÐ¶Ð°Ñ", "Ð±Ð°Ð³", "Ð»Ð°Ð³Ð°", "Ð³Ð»ÑŽÑ‡", "Ð½ÐµÐ½Ð°Ð²Ð¸Ð¶"}

def sentiment(text: str) -> str:
    t = text.lower()
    score = 0
    for w in POSITIVE:
        if w in t:
            score += 1
    for w in NEGATIVE:
        if w in t:
            score -= 1
    if score > 0:
        return "positive"
    if score < 0:
        return "negative"
    return "neutral"

# ================= SCRAPER =================
@st.cache_data(show_spinner=False)
def fetch_reviews(app_id: str, regions: tuple):
    all_reviews = []
    seen = set()

    progress = st.progress(0)
    status = st.empty()

    total = len(regions) * 50
    step = 0

    for region in regions:
        for page in range(1, 51):

            if st.session_state.stop:
                return pd.DataFrame(all_reviews)

            url = (
                f"https://itunes.apple.com/{region}/rss/customerreviews/"
                f"page={page}/id={app_id}/sortby=mostrecent/json"
            )

            try:
                r = requests.get(url, timeout=10)
                if r.status_code != 200:
                    break

                entries = r.json().get("feed", {}).get("entry", [])
                if page == 1:
                    entries = entries[1:]
                if not entries:
                    break

                for e in entries:
                    rid = e["id"]["label"]
                    if rid in seen:
                        continue

                    text = e["content"]["label"]
                    all_reviews.append({
                        "review_id": rid,
                        "rating": int(e["im:rating"]["label"]),
                        "review_text": text,
                        "sentiment": sentiment(text),
                        "review_date": e["updated"]["label"],
                        "region": region.upper()
                    })
                    seen.add(rid)

                step += 1
                progress.progress(min(step / total, 1.0))
                status.write(f"ðŸŒ {region.upper()} â€¢ ÑÑ‚Ñ€. {page}")

                time.sleep(0.05)

            except Exception:
                break

    return pd.DataFrame(all_reviews)

# ================= RUN =================
if START:

    st.session_state.stop = False

    if not APP_ID.isdigit():
        st.error("âŒ App ID Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ñ‡Ð¸ÑÐ»Ð¾Ð¼")
        st.stop()

    if not REGIONS:
        st.error("âŒ Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ€ÐµÐ³Ð¸Ð¾Ð½")
        st.stop()

    with st.spinner("ðŸ”„ Ð¡Ð±Ð¾Ñ€ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²..."):
        df = fetch_reviews(APP_ID, tuple(REGIONS))

    if df.empty:
        st.warning("âš ï¸ ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        st.stop()

    df["review_date"] = pd.to_datetime(df["review_date"], errors="coerce")
    df.dropna(subset=["review_date"], inplace=True)

    st.success(f"âœ… Ð¡Ð¾Ð±Ñ€Ð°Ð½Ð¾ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²: {len(df)}")

    # ================= DASHBOARD =================
    st.divider()
    st.header("ðŸ“Š Ð”Ð°ÑˆÐ±Ð¾Ñ€Ð´")

    c1, c2, c3 = st.columns(3)
    c1.metric("Ð’ÑÐµÐ³Ð¾ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²", len(df))
    c2.metric("Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³", round(df["rating"].mean(), 2))
    c3.metric("Ð ÐµÐ³Ð¸Ð¾Ð½Ð¾Ð²", df["region"].nunique())

    st.subheader("â­ Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¾Ð²")
    st.bar_chart(df["rating"].value_counts().sort_index())

    st.subheader("ðŸ’¬ Ð¢Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²")
    st.bar_chart(df["sentiment"].value_counts())

    st.subheader("ðŸŒ ÐžÑ‚Ð·Ñ‹Ð²Ñ‹ Ð¿Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°Ð¼")
    st.bar_chart(df["region"].value_counts())

    st.subheader("ðŸ“ˆ Ð”Ð¸Ð½Ð°Ð¼Ð¸ÐºÐ° Ð¾Ñ‚Ð·Ñ‹Ð²Ð¾Ð²")
    daily = df.groupby(df["review_date"].dt.date).size()
    st.line_chart(daily)

    st.subheader("ðŸŒŽ Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ Ð¿Ð¾ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°Ð¼")
    avg_region = df.groupby("region")["rating"].mean().sort_values()
    st.bar_chart(avg_region)

    # ================= EXPORT =================
    st.divider()
    csv = df.to_csv(index=False, encoding="utf-8-sig")
    xlsx = BytesIO()
    with pd.ExcelWriter(xlsx, engine="openpyxl") as w:
        df.to_excel(w, index=False)
    xlsx.seek(0)

    c1, c2 = st.columns(2)
    c1.download_button("â¬‡ï¸ CSV", csv, "reviews.csv", "text/csv", use_container_width=True)
    c2.download_button("â¬‡ï¸ XLSX", xlsx, "reviews.xlsx",
                       "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                       use_container_width=True)

    st.subheader("ðŸ“„ ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
    st.dataframe(df.head(100), use_container_width=True)
