import streamlit as st
import pandas as pd
import requests
import time
import re
import hashlib
from collections import Counter
from io import BytesIO

# ================= –ù–ê–°–¢–†–û–ô–ö–ò =================
st.set_page_config(
    page_title="App Store Reviews Analyzer",
    layout="wide"
)

st.title("üì± –ê–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ App Store")
st.caption("–°–±–æ—Ä –∏ –∞–Ω–∞–ª–∏–∑ —Ä—É—Å—Å–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤ —á–µ—Ä–µ–∑ Apple RSS API")

# ================= –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï =================
CYRILLIC_RE = re.compile(r"[–∞-—è–ê-–Ø—ë–Å]")
_lang_cache = {}

def is_russian(text: str) -> bool:
    if not text:
        return False
    key = hashlib.md5(text.encode("utf-8")).hexdigest()
    if key in _lang_cache:
        return _lang_cache[key]
    result = bool(CYRILLIC_RE.search(text))
    _lang_cache[key] = result
    return result


NEGATIVE = {
    "–±–∞–≥": "–ë–∞–≥–∏",
    "–æ—à–∏–±": "–û—à–∏–±–∫–∏",
    "–≤—ã–ª–µ—Ç": "–ö—Ä–∞—à–∏",
    "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç": "–ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç",
    "–º–µ–¥–ª–µ–Ω": "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
    "–ª–∞–≥–∞": "–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
    "—Ä–µ–∫–ª–∞–º–∞": "–†–µ–∫–ª–∞–º–∞",
    "–ø–æ–¥–ø–∏—Å": "–ü–æ–¥–ø–∏—Å–∫–∞",
}

POSITIVE = {
    "—É–¥–æ–±": "–£–¥–æ–±—Å—Ç–≤–æ",
    "–æ—Ç–ª–∏—á": "–ö–∞—á–µ—Å—Ç–≤–æ",
    "–∫–ª–∞—Å—Å": "–ö–∞—á–µ—Å—Ç–≤–æ",
    "–ø–æ–ª–µ–∑": "–ü–æ–ª—å–∑–∞",
    "–±—ã—Å—Ç—Ä–æ": "–°–∫–æ—Ä–æ—Å—Ç—å",
}

def extract_problems_and_pluses(texts):
    problems = Counter()
    pluses = Counter()
    for t in texts:
        low = t.lower()
        for k, v in NEGATIVE.items():
            if k in low:
                problems[v] += 1
        for k, v in POSITIVE.items():
            if k in low:
                pluses[v] += 1
    return problems, pluses


def collect_reviews(app_id: str, regions: list, stop_flag):
    all_reviews = []
    seen = set()

    for country in regions:
        page = 1
        while True:
            if stop_flag():
                return all_reviews

            url = (
                f"https://itunes.apple.com/{country}/rss/customerreviews/"
                f"page={page}/id={app_id}/sortby=mostrecent/json"
            )

            try:
                r = requests.get(url, timeout=15)
                if r.status_code != 200:
                    break

                feed = r.json().get("feed", {})
                entries = feed.get("entry", [])
                if not entries:
                    break

                if page == 1:
                    entries = entries[1:]  # metadata

                for e in entries:
                    rid = e["id"]["label"]
                    if rid in seen:
                        continue

                    text = e["content"]["label"]
                    if is_russian(text):
                        all_reviews.append({
                            "review_id": rid,
                            "author": e["author"]["name"]["label"],
                            "rating": int(e["im:rating"]["label"]),
                            "title": e["title"]["label"],
                            "review_text": text,
                            "review_date": e["updated"]["label"],
                            "version": e["im:version"]["label"],
                            "region": country
                        })
                        seen.add(rid)

                page += 1
                time.sleep(0.2)

            except Exception:
                break

    return all_reviews


# ================= UI =================
APP_ID = st.text_input("App ID (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)", placeholder="686449807")

REGIONS = st.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–≥–∏–æ–Ω—ã",
    ["ru", "us", "kz", "ua", "by", "de", "fr"],
    default=["ru"]
)

if "stop" not in st.session_state:
    st.session_state.stop = False

col1, col2 = st.columns(2)
with col1:
    start_btn = st.button("üöÄ –ù–∞—á–∞—Ç—å —Å–±–æ—Ä")
with col2:
    stop_btn = st.button("üõë –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å")
    if stop_btn:
        st.session_state.stop = True

def stop_flag():
    return st.session_state.stop


@st.cache_data(show_spinner=False)
def load_data(app_id, regions):
    return collect_reviews(app_id, list(regions), stop_flag)


# ================= –õ–û–ì–ò–ö–ê =================
if start_btn:
    st.session_state.stop = False

    if not APP_ID.isdigit():
        st.error("‚ùå App ID –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã")
        st.stop()

    with st.spinner("‚è≥ –°–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤..."):
        data = load_data(APP_ID, tuple(REGIONS))

    if not data:
        st.warning("–û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        st.stop()

    df = pd.DataFrame(data).drop_duplicates("review_id")

    # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï
    df["review_date"] = pd.to_datetime(df["review_date"], errors="coerce")
    df["review_date"] = df["review_date"].dt.strftime("%Y-%m-%d %H:%M:%S")

    df["rating"] = pd.to_numeric(df["rating"], errors="coerce")

    st.success(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(df)}")

    # ===== –ú–µ—Ç—Ä–∏–∫–∏ =====
    st.subheader("üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    st.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥", round(df["rating"].mean(), 2))

    st.subheader("üåç –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º")
    st.bar_chart(df.groupby("region")["rating"].mean())

    st.subheader("‚≠ê –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫")
    st.bar_chart(df["rating"].value_counts().sort_index())

    # ===== –ê–Ω–∞–ª–∏–∑ =====
    problems, pluses = extract_problems_and_pluses(df["review_text"])

    c1, c2 = st.columns(2)
    with c1:
        st.subheader("‚ùå –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")
        for k, v in problems.most_common(5):
            st.write(f"{k}: {v}")

    with c2:
        st.subheader("‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ –ø–ª—é—Å—ã")
        for k, v in pluses.most_common(5):
            st.write(f"{k}: {v}")

    # ===== –≠–∫—Å–ø–æ—Ä—Ç =====
    csv = df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV", csv, "reviews.csv")

    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False, sheet_name="Reviews")

    st.download_button(
        "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å XLSX",
        buffer.getvalue(),
        "reviews.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    st.subheader("üîç –ü—Ä–∏–º–µ—Ä –æ—Ç–∑—ã–≤–æ–≤")
    st.dataframe(df.head(50))
